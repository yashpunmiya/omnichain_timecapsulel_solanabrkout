{"ast":null,"code":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/* replacement start */\nconst process = require('process/');\n\n/* replacement end */\n\nconst {\n  ArrayPrototypeIndexOf,\n  NumberIsInteger,\n  NumberIsNaN,\n  NumberParseInt,\n  ObjectDefineProperties,\n  ObjectKeys,\n  ObjectSetPrototypeOf,\n  Promise,\n  SafeSet,\n  SymbolAsyncDispose,\n  SymbolAsyncIterator,\n  Symbol\n} = require('../../ours/primordials');\nmodule.exports = Readable;\nReadable.ReadableState = ReadableState;\nconst {\n  EventEmitter: EE\n} = require('events');\nconst {\n  Stream,\n  prependListener\n} = require('./legacy');\nconst {\n  Buffer\n} = require('buffer');\nconst {\n  addAbortSignal\n} = require('./add-abort-signal');\nconst eos = require('./end-of-stream');\nlet debug = require('../../ours/util').debuglog('stream', fn => {\n  debug = fn;\n});\nconst BufferList = require('./buffer_list');\nconst destroyImpl = require('./destroy');\nconst {\n  getHighWaterMark,\n  getDefaultHighWaterMark\n} = require('./state');\nconst {\n  aggregateTwoErrors,\n  codes: {\n    ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_OUT_OF_RANGE,\n    ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT\n  },\n  AbortError\n} = require('../../ours/errors');\nconst {\n  validateObject\n} = require('../validators');\nconst kPaused = Symbol('kPaused');\nconst {\n  StringDecoder\n} = require('string_decoder/');\nconst from = require('./from');\nObjectSetPrototypeOf(Readable.prototype, Stream.prototype);\nObjectSetPrototypeOf(Readable, Stream);\nconst nop = () => {};\nconst {\n  errorOrDestroy\n} = destroyImpl;\nconst kObjectMode = 1 << 0;\nconst kEnded = 1 << 1;\nconst kEndEmitted = 1 << 2;\nconst kReading = 1 << 3;\nconst kConstructed = 1 << 4;\nconst kSync = 1 << 5;\nconst kNeedReadable = 1 << 6;\nconst kEmittedReadable = 1 << 7;\nconst kReadableListening = 1 << 8;\nconst kResumeScheduled = 1 << 9;\nconst kErrorEmitted = 1 << 10;\nconst kEmitClose = 1 << 11;\nconst kAutoDestroy = 1 << 12;\nconst kDestroyed = 1 << 13;\nconst kClosed = 1 << 14;\nconst kCloseEmitted = 1 << 15;\nconst kMultiAwaitDrain = 1 << 16;\nconst kReadingMore = 1 << 17;\nconst kDataEmitted = 1 << 18;\n\n// TODO(benjamingr) it is likely slower to do it this way than with free functions\nfunction makeBitMapDescriptor(bit) {\n  return {\n    enumerable: false,\n    get() {\n      return (this.state & bit) !== 0;\n    },\n    set(value) {\n      if (value) this.state |= bit;else this.state &= ~bit;\n    }\n  };\n}\nObjectDefineProperties(ReadableState.prototype, {\n  objectMode: makeBitMapDescriptor(kObjectMode),\n  ended: makeBitMapDescriptor(kEnded),\n  endEmitted: makeBitMapDescriptor(kEndEmitted),\n  reading: makeBitMapDescriptor(kReading),\n  // Stream is still being constructed and cannot be\n  // destroyed until construction finished or failed.\n  // Async construction is opt in, therefore we start as\n  // constructed.\n  constructed: makeBitMapDescriptor(kConstructed),\n  // A flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  sync: makeBitMapDescriptor(kSync),\n  // Whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  needReadable: makeBitMapDescriptor(kNeedReadable),\n  emittedReadable: makeBitMapDescriptor(kEmittedReadable),\n  readableListening: makeBitMapDescriptor(kReadableListening),\n  resumeScheduled: makeBitMapDescriptor(kResumeScheduled),\n  // True if the error was already emitted and should not be thrown again.\n  errorEmitted: makeBitMapDescriptor(kErrorEmitted),\n  emitClose: makeBitMapDescriptor(kEmitClose),\n  autoDestroy: makeBitMapDescriptor(kAutoDestroy),\n  // Has it been destroyed.\n  destroyed: makeBitMapDescriptor(kDestroyed),\n  // Indicates whether the stream has finished destroying.\n  closed: makeBitMapDescriptor(kClosed),\n  // True if close has been emitted or would have been emitted\n  // depending on emitClose.\n  closeEmitted: makeBitMapDescriptor(kCloseEmitted),\n  multiAwaitDrain: makeBitMapDescriptor(kMultiAwaitDrain),\n  // If true, a maybeReadMore has been scheduled.\n  readingMore: makeBitMapDescriptor(kReadingMore),\n  dataEmitted: makeBitMapDescriptor(kDataEmitted)\n});\nfunction ReadableState(options, stream, isDuplex) {\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof require('./duplex');\n\n  // Bit map field to store ReadableState more effciently with 1 bit per field\n  // instead of a V8 slot per field.\n  this.state = kEmitClose | kAutoDestroy | kConstructed | kSync;\n  // Object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away.\n  if (options && options.objectMode) this.state |= kObjectMode;\n  if (isDuplex && options && options.readableObjectMode) this.state |= kObjectMode;\n\n  // The point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  this.highWaterMark = options ? getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex) : getDefaultHighWaterMark(false);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift().\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = [];\n  this.flowing = null;\n  this[kPaused] = null;\n\n  // Should close be emitted on destroy. Defaults to true.\n  if (options && options.emitClose === false) this.state &= ~kEmitClose;\n\n  // Should .destroy() be called after 'end' (and potentially 'finish').\n  if (options && options.autoDestroy === false) this.state &= ~kAutoDestroy;\n\n  // Indicates whether the stream has errored. When true no further\n  // _read calls, 'data' or 'readable' events should occur. This is needed\n  // since when autoDestroy is disabled we need a way to tell whether the\n  // stream has failed.\n  this.errored = null;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options && options.defaultEncoding || 'utf8';\n\n  // Ref the piped dest which we need a drain event on it\n  // type: null | Writable | Set<Writable>.\n  this.awaitDrainWriters = null;\n  this.decoder = null;\n  this.encoding = null;\n  if (options && options.encoding) {\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\nfunction Readable(options) {\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5.\n  const isDuplex = this instanceof require('./duplex');\n  this._readableState = new ReadableState(options, this, isDuplex);\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.construct === 'function') this._construct = options.construct;\n    if (options.signal && !isDuplex) addAbortSignal(options.signal, this);\n  }\n  Stream.call(this, options);\n  destroyImpl.construct(this, () => {\n    if (this._readableState.needReadable) {\n      maybeReadMore(this, this._readableState);\n    }\n  });\n}\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n};\nReadable.prototype[EE.captureRejectionSymbol] = function (err) {\n  this.destroy(err);\n};\nReadable.prototype[SymbolAsyncDispose] = function () {\n  let error;\n  if (!this.destroyed) {\n    error = this.readableEnded ? null : new AbortError();\n    this.destroy(error);\n  }\n  return new Promise((resolve, reject) => eos(this, err => err && err !== error ? reject(err) : resolve(null)));\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  return readableAddChunk(this, chunk, encoding, false);\n};\n\n// Unshift should *always* be something directly out of read().\nReadable.prototype.unshift = function (chunk, encoding) {\n  return readableAddChunk(this, chunk, encoding, true);\n};\nfunction readableAddChunk(stream, chunk, encoding, addToFront) {\n  debug('readableAddChunk', chunk);\n  const state = stream._readableState;\n  let err;\n  if ((state.state & kObjectMode) === 0) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (state.encoding !== encoding) {\n        if (addToFront && state.encoding) {\n          // When unshifting, if state.encoding is set, we have to save\n          // the string in the BufferList with the state encoding.\n          chunk = Buffer.from(chunk, encoding).toString(state.encoding);\n        } else {\n          chunk = Buffer.from(chunk, encoding);\n          encoding = '';\n        }\n      }\n    } else if (chunk instanceof Buffer) {\n      encoding = '';\n    } else if (Stream._isUint8Array(chunk)) {\n      chunk = Stream._uint8ArrayToBuffer(chunk);\n      encoding = '';\n    } else if (chunk != null) {\n      err = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n    }\n  }\n  if (err) {\n    errorOrDestroy(stream, err);\n  } else if (chunk === null) {\n    state.state &= ~kReading;\n    onEofChunk(stream, state);\n  } else if ((state.state & kObjectMode) !== 0 || chunk && chunk.length > 0) {\n    if (addToFront) {\n      if ((state.state & kEndEmitted) !== 0) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else if (state.destroyed || state.errored) return false;else addChunk(stream, state, chunk, true);\n    } else if (state.ended) {\n      errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n    } else if (state.destroyed || state.errored) {\n      return false;\n    } else {\n      state.state &= ~kReading;\n      if (state.decoder && !encoding) {\n        chunk = state.decoder.write(chunk);\n        if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n      } else {\n        addChunk(stream, state, chunk, false);\n      }\n    }\n  } else if (!addToFront) {\n    state.state &= ~kReading;\n    maybeReadMore(stream, state);\n  }\n\n  // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync && stream.listenerCount('data') > 0) {\n    // Use the guard to avoid creating `Set()` repeatedly\n    // when we have multiple pipes.\n    if ((state.state & kMultiAwaitDrain) !== 0) {\n      state.awaitDrainWriters.clear();\n    } else {\n      state.awaitDrainWriters = null;\n    }\n    state.dataEmitted = true;\n    stream.emit('data', chunk);\n  } else {\n    // Update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if ((state.state & kNeedReadable) !== 0) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\nReadable.prototype.isPaused = function () {\n  const state = this._readableState;\n  return state[kPaused] === true || state.flowing === false;\n};\n\n// Backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  const decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder;\n  // If setEncoding(null), decoder.encoding equals utf8.\n  this._readableState.encoding = this._readableState.decoder.encoding;\n  const buffer = this._readableState.buffer;\n  // Iterate over current buffer to convert already stored Buffers:\n  let content = '';\n  for (const data of buffer) {\n    content += decoder.write(data);\n  }\n  buffer.clear();\n  if (content !== '') buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n};\n\n// Don't raise the hwm > 1GB.\nconst MAX_HWM = 0x40000000;\nfunction computeNewHighWaterMark(n) {\n  if (n > MAX_HWM) {\n    throw new ERR_OUT_OF_RANGE('size', '<= 1GiB', n);\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts.\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if ((state.state & kObjectMode) !== 0) return 1;\n  if (NumberIsNaN(n)) {\n    // Only flow one buffer at a time.\n    if (state.flowing && state.length) return state.buffer.first().length;\n    return state.length;\n  }\n  if (n <= state.length) return n;\n  return state.ended ? state.length : 0;\n}\n\n// You can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  // Same as parseInt(undefined, 10), however V8 7.3 performance regressed\n  // in this scenario, so we are doing it manually.\n  if (n === undefined) {\n    n = NaN;\n  } else if (!NumberIsInteger(n)) {\n    n = NumberParseInt(n, 10);\n  }\n  const state = this._readableState;\n  const nOrig = n;\n\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n !== 0) state.state &= ~kEmittedReadable;\n\n  // If we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n  n = howMuchToRead(n, state);\n\n  // If we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  let doRead = (state.state & kNeedReadable) !== 0;\n  debug('need readable', doRead);\n\n  // If we currently have less than the highWaterMark, then also read some.\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // However, if we've ended, then there's no point, if we're already\n  // reading, then it's unnecessary, if we're constructing we have to wait,\n  // and if we're destroyed or errored, then it's not allowed,\n  if (state.ended || state.reading || state.destroyed || state.errored || !state.constructed) {\n    doRead = false;\n    debug('reading, ended or constructing', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.state |= kReading | kSync;\n    // If the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.state |= kNeedReadable;\n\n    // Call internal read method\n    try {\n      this._read(state.highWaterMark);\n    } catch (err) {\n      errorOrDestroy(this, err);\n    }\n    state.state &= ~kSync;\n\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n  let ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    if (state.multiAwaitDrain) {\n      state.awaitDrainWriters.clear();\n    } else {\n      state.awaitDrainWriters = null;\n    }\n  }\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n  if (ret !== null && !state.errorEmitted && !state.closeEmitted) {\n    state.dataEmitted = true;\n    this.emit('data', ret);\n  }\n  return ret;\n};\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n  if (state.decoder) {\n    const chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n  if (state.sync) {\n    // If we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call.\n    emitReadable(stream);\n  } else {\n    // Emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n    state.emittedReadable = true;\n    // We have to emit readable now that we are EOF. Modules\n    // in the ecosystem (e.g. dicer) rely on this event being sync.\n    emitReadable_(stream);\n  }\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  const state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\nfunction emitReadable_(stream) {\n  const state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n  if (!state.destroyed && !state.errored && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  }\n\n  // The stream needs another readable event if:\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n}\n\n// At this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore && state.constructed) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    const len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // Didn't get any data, stop spinning.\n      break;\n  }\n  state.readingMore = false;\n}\n\n// Abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  throw new ERR_METHOD_NOT_IMPLEMENTED('_read()');\n};\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  const src = this;\n  const state = this._readableState;\n  if (state.pipes.length === 1) {\n    if (!state.multiAwaitDrain) {\n      state.multiAwaitDrain = true;\n      state.awaitDrainWriters = new SafeSet(state.awaitDrainWriters ? [state.awaitDrainWriters] : []);\n    }\n  }\n  state.pipes.push(dest);\n  debug('pipe count=%d opts=%j', state.pipes.length, pipeOpts);\n  const doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  const endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n  let ondrain;\n  let cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // Cleanup event handlers once the pipe is broken.\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    if (ondrain) {\n      dest.removeListener('drain', ondrain);\n    }\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true;\n\n    // If the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (ondrain && state.awaitDrainWriters && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n  function pause() {\n    // If the user unpiped during `dest.write()`, it is possible\n    // to get stuck in a permanently paused state if that write\n    // also returned false.\n    // => Check whether `dest` is still a piping destination.\n    if (!cleanedUp) {\n      if (state.pipes.length === 1 && state.pipes[0] === dest) {\n        debug('false write response, pause', 0);\n        state.awaitDrainWriters = dest;\n        state.multiAwaitDrain = false;\n      } else if (state.pipes.length > 1 && state.pipes.includes(dest)) {\n        debug('false write response, pause', state.awaitDrainWriters.size);\n        state.awaitDrainWriters.add(dest);\n      }\n      src.pause();\n    }\n    if (!ondrain) {\n      // When the dest drains, it reduces the awaitDrain counter\n      // on the source.  This would be more elegant with a .once()\n      // handler in flow(), but adding and removing repeatedly is\n      // too slow.\n      ondrain = pipeOnDrain(src, dest);\n      dest.on('drain', ondrain);\n    }\n  }\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    const ret = dest.write(chunk);\n    debug('dest.write', ret);\n    if (ret === false) {\n      pause();\n    }\n  }\n\n  // If the dest has an error, then stop piping into it.\n  // However, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (dest.listenerCount('error') === 0) {\n      const s = dest._writableState || dest._readableState;\n      if (s && !s.errorEmitted) {\n        // User incorrectly emitted 'error' directly on the stream.\n        errorOrDestroy(dest, er);\n      } else {\n        dest.emit('error', er);\n      }\n    }\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // Tell the dest that it's being piped to.\n  dest.emit('pipe', src);\n\n  // Start the flow if it hasn't been started already.\n\n  if (dest.writableNeedDrain === true) {\n    pause();\n  } else if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n  return dest;\n};\nfunction pipeOnDrain(src, dest) {\n  return function pipeOnDrainFunctionResult() {\n    const state = src._readableState;\n\n    // `ondrain` will call directly,\n    // `this` maybe not a reference to dest,\n    // so we use the real dest here.\n    if (state.awaitDrainWriters === dest) {\n      debug('pipeOnDrain', 1);\n      state.awaitDrainWriters = null;\n    } else if (state.multiAwaitDrain) {\n      debug('pipeOnDrain', state.awaitDrainWriters.size);\n      state.awaitDrainWriters.delete(dest);\n    }\n    if ((!state.awaitDrainWriters || state.awaitDrainWriters.size === 0) && src.listenerCount('data')) {\n      src.resume();\n    }\n  };\n}\nReadable.prototype.unpipe = function (dest) {\n  const state = this._readableState;\n  const unpipeInfo = {\n    hasUnpiped: false\n  };\n\n  // If we're not piping anywhere, then do nothing.\n  if (state.pipes.length === 0) return this;\n  if (!dest) {\n    // remove all.\n    const dests = state.pipes;\n    state.pipes = [];\n    this.pause();\n    for (let i = 0; i < dests.length; i++) dests[i].emit('unpipe', this, {\n      hasUnpiped: false\n    });\n    return this;\n  }\n\n  // Try to find the right one.\n  const index = ArrayPrototypeIndexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  if (state.pipes.length === 0) this.pause();\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n};\n\n// Set up data events if they are asked for\n// Ensure readable listeners eventually get something.\nReadable.prototype.on = function (ev, fn) {\n  const res = Stream.prototype.on.call(this, ev, fn);\n  const state = this._readableState;\n  if (ev === 'data') {\n    // Update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0;\n\n    // Try start flowing on next tick if stream isn't explicitly paused.\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\nReadable.prototype.removeListener = function (ev, fn) {\n  const res = Stream.prototype.removeListener.call(this, ev, fn);\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n  return res;\n};\nReadable.prototype.off = Readable.prototype.removeListener;\nReadable.prototype.removeAllListeners = function (ev) {\n  const res = Stream.prototype.removeAllListeners.apply(this, arguments);\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n  return res;\n};\nfunction updateReadableListening(self) {\n  const state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n  if (state.resumeScheduled && state[kPaused] === false) {\n    // Flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true;\n\n    // Crude way to check if we should resume.\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  } else if (!state.readableListening) {\n    state.flowing = null;\n  }\n}\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  const state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    // We flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume().\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n  state[kPaused] = false;\n  return this;\n};\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n  if (!state.reading) {\n    stream.read(0);\n  }\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  this._readableState[kPaused] = true;\n  return this;\n};\nfunction flow(stream) {\n  const state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null);\n}\n\n// Wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  let paused = false;\n\n  // TODO (ronag): Should this.destroy(err) emit\n  // 'error' on the wrapped stream? Would require\n  // a static factory method, e.g. Readable.wrap(stream).\n\n  stream.on('data', chunk => {\n    if (!this.push(chunk) && stream.pause) {\n      paused = true;\n      stream.pause();\n    }\n  });\n  stream.on('end', () => {\n    this.push(null);\n  });\n  stream.on('error', err => {\n    errorOrDestroy(this, err);\n  });\n  stream.on('close', () => {\n    this.destroy();\n  });\n  stream.on('destroy', () => {\n    this.destroy();\n  });\n  this._read = () => {\n    if (paused && stream.resume) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  // Proxy all the other methods. Important when wrapping filters and duplexes.\n  const streamKeys = ObjectKeys(stream);\n  for (let j = 1; j < streamKeys.length; j++) {\n    const i = streamKeys[j];\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = stream[i].bind(stream);\n    }\n  }\n  return this;\n};\nReadable.prototype[SymbolAsyncIterator] = function () {\n  return streamToAsyncIterator(this);\n};\nReadable.prototype.iterator = function (options) {\n  if (options !== undefined) {\n    validateObject(options, 'options');\n  }\n  return streamToAsyncIterator(this, options);\n};\nfunction streamToAsyncIterator(stream, options) {\n  if (typeof stream.read !== 'function') {\n    stream = Readable.wrap(stream, {\n      objectMode: true\n    });\n  }\n  const iter = createAsyncIterator(stream, options);\n  iter.stream = stream;\n  return iter;\n}\nasync function* createAsyncIterator(stream, options) {\n  let callback = nop;\n  function next(resolve) {\n    if (this === stream) {\n      callback();\n      callback = nop;\n    } else {\n      callback = resolve;\n    }\n  }\n  stream.on('readable', next);\n  let error;\n  const cleanup = eos(stream, {\n    writable: false\n  }, err => {\n    error = err ? aggregateTwoErrors(error, err) : null;\n    callback();\n    callback = nop;\n  });\n  try {\n    while (true) {\n      const chunk = stream.destroyed ? null : stream.read();\n      if (chunk !== null) {\n        yield chunk;\n      } else if (error) {\n        throw error;\n      } else if (error === null) {\n        return;\n      } else {\n        await new Promise(next);\n      }\n    }\n  } catch (err) {\n    error = aggregateTwoErrors(error, err);\n    throw error;\n  } finally {\n    if ((error || (options === null || options === undefined ? undefined : options.destroyOnReturn) !== false) && (error === undefined || stream._readableState.autoDestroy)) {\n      destroyImpl.destroyer(stream, null);\n    } else {\n      stream.off('readable', next);\n      cleanup();\n    }\n  }\n}\n\n// Making it explicit these properties are not enumerable\n// because otherwise some prototype manipulation in\n// userland will fail.\nObjectDefineProperties(Readable.prototype, {\n  readable: {\n    __proto__: null,\n    get() {\n      const r = this._readableState;\n      // r.readable === false means that this is part of a Duplex stream\n      // where the readable side was disabled upon construction.\n      // Compat. The user might manually disable readable side through\n      // deprecated setter.\n      return !!r && r.readable !== false && !r.destroyed && !r.errorEmitted && !r.endEmitted;\n    },\n    set(val) {\n      // Backwards compat.\n      if (this._readableState) {\n        this._readableState.readable = !!val;\n      }\n    }\n  },\n  readableDidRead: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.dataEmitted;\n    }\n  },\n  readableAborted: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return !!(this._readableState.readable !== false && (this._readableState.destroyed || this._readableState.errored) && !this._readableState.endEmitted);\n    }\n  },\n  readableHighWaterMark: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.highWaterMark;\n    }\n  },\n  readableBuffer: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState && this._readableState.buffer;\n    }\n  },\n  readableFlowing: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.flowing;\n    },\n    set: function (state) {\n      if (this._readableState) {\n        this._readableState.flowing = state;\n      }\n    }\n  },\n  readableLength: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState.length;\n    }\n  },\n  readableObjectMode: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.objectMode : false;\n    }\n  },\n  readableEncoding: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.encoding : null;\n    }\n  },\n  errored: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.errored : null;\n    }\n  },\n  closed: {\n    __proto__: null,\n    get() {\n      return this._readableState ? this._readableState.closed : false;\n    }\n  },\n  destroyed: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.destroyed : false;\n    },\n    set(value) {\n      // We ignore the value if the stream\n      // has not been initialized yet.\n      if (!this._readableState) {\n        return;\n      }\n\n      // Backward compatibility, the user is explicitly\n      // managing destroyed.\n      this._readableState.destroyed = value;\n    }\n  },\n  readableEnded: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.endEmitted : false;\n    }\n  }\n});\nObjectDefineProperties(ReadableState.prototype, {\n  // Legacy getter for `pipesCount`.\n  pipesCount: {\n    __proto__: null,\n    get() {\n      return this.pipes.length;\n    }\n  },\n  // Legacy property for `paused`.\n  paused: {\n    __proto__: null,\n    get() {\n      return this[kPaused] !== false;\n    },\n    set(value) {\n      this[kPaused] = !!value;\n    }\n  }\n});\n\n// Exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered.\n  if (state.length === 0) return null;\n  let ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // Read it all, truncate the list.\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list.\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\nfunction endReadable(stream) {\n  const state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length);\n\n  // Check that we didn't get one last unshift.\n  if (!state.errored && !state.closeEmitted && !state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.emit('end');\n    if (stream.writable && stream.allowHalfOpen === false) {\n      process.nextTick(endWritableNT, stream);\n    } else if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well.\n      const wState = stream._writableState;\n      const autoDestroy = !wState || wState.autoDestroy && (\n      // We don't expect the writable to ever 'finish'\n      // if writable is explicitly set to false.\n      wState.finished || wState.writable === false);\n      if (autoDestroy) {\n        stream.destroy();\n      }\n    }\n  }\n}\nfunction endWritableNT(stream) {\n  const writable = stream.writable && !stream.writableEnded && !stream.destroyed;\n  if (writable) {\n    stream.end();\n  }\n}\nReadable.from = function (iterable, opts) {\n  return from(Readable, iterable, opts);\n};\nlet webStreamsAdapters;\n\n// Lazy to avoid circular references\nfunction lazyWebStreams() {\n  if (webStreamsAdapters === undefined) webStreamsAdapters = {};\n  return webStreamsAdapters;\n}\nReadable.fromWeb = function (readableStream, options) {\n  return lazyWebStreams().newStreamReadableFromReadableStream(readableStream, options);\n};\nReadable.toWeb = function (streamReadable, options) {\n  return lazyWebStreams().newReadableStreamFromStreamReadable(streamReadable, options);\n};\nReadable.wrap = function (src, options) {\n  var _ref, _src$readableObjectMo;\n  return new Readable({\n    objectMode: (_ref = (_src$readableObjectMo = src.readableObjectMode) !== null && _src$readableObjectMo !== undefined ? _src$readableObjectMo : src.objectMode) !== null && _ref !== undefined ? _ref : true,\n    ...options,\n    destroy(err, callback) {\n      destroyImpl.destroyer(src, err);\n      callback(err);\n    }\n  }).wrap(src);\n};","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}