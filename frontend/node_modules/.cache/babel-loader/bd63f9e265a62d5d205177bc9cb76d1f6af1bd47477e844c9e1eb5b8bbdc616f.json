{"ast":null,"code":"/* replacement start */\n\nconst process = require('process/')\n\n/* replacement end */\n// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n;\n'use strict';\nconst {\n  ArrayIsArray,\n  Promise,\n  SymbolAsyncIterator,\n  SymbolDispose\n} = require('../../ours/primordials');\nconst eos = require('./end-of-stream');\nconst {\n  once\n} = require('../../ours/util');\nconst destroyImpl = require('./destroy');\nconst Duplex = require('./duplex');\nconst {\n  aggregateTwoErrors,\n  codes: {\n    ERR_INVALID_ARG_TYPE,\n    ERR_INVALID_RETURN_VALUE,\n    ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED,\n    ERR_STREAM_PREMATURE_CLOSE\n  },\n  AbortError\n} = require('../../ours/errors');\nconst {\n  validateFunction,\n  validateAbortSignal\n} = require('../validators');\nconst {\n  isIterable,\n  isReadable,\n  isReadableNodeStream,\n  isNodeStream,\n  isTransformStream,\n  isWebStream,\n  isReadableStream,\n  isReadableFinished\n} = require('./utils');\nconst AbortController = globalThis.AbortController || require('abort-controller').AbortController;\nlet PassThrough;\nlet Readable;\nlet addAbortListener;\nfunction destroyer(stream, reading, writing) {\n  let finished = false;\n  stream.on('close', () => {\n    finished = true;\n  });\n  const cleanup = eos(stream, {\n    readable: reading,\n    writable: writing\n  }, err => {\n    finished = !err;\n  });\n  return {\n    destroy: err => {\n      if (finished) return;\n      finished = true;\n      destroyImpl.destroyer(stream, err || new ERR_STREAM_DESTROYED('pipe'));\n    },\n    cleanup\n  };\n}\nfunction popCallback(streams) {\n  // Streams should never be an empty array. It should always contain at least\n  // a single stream. Therefore optimize for the average case instead of\n  // checking for length === 0 as well.\n  validateFunction(streams[streams.length - 1], 'streams[stream.length - 1]');\n  return streams.pop();\n}\nfunction makeAsyncIterable(val) {\n  if (isIterable(val)) {\n    return val;\n  } else if (isReadableNodeStream(val)) {\n    // Legacy streams are not Iterable.\n    return fromReadable(val);\n  }\n  throw new ERR_INVALID_ARG_TYPE('val', ['Readable', 'Iterable', 'AsyncIterable'], val);\n}\nasync function* fromReadable(val) {\n  if (!Readable) {\n    Readable = require('./readable');\n  }\n  yield* Readable.prototype[SymbolAsyncIterator].call(val);\n}\nasync function pumpToNode(iterable, writable, finish, {\n  end\n}) {\n  let error;\n  let onresolve = null;\n  const resume = err => {\n    if (err) {\n      error = err;\n    }\n    if (onresolve) {\n      const callback = onresolve;\n      onresolve = null;\n      callback();\n    }\n  };\n  const wait = () => new Promise((resolve, reject) => {\n    if (error) {\n      reject(error);\n    } else {\n      onresolve = () => {\n        if (error) {\n          reject(error);\n        } else {\n          resolve();\n        }\n      };\n    }\n  });\n  writable.on('drain', resume);\n  const cleanup = eos(writable, {\n    readable: false\n  }, resume);\n  try {\n    if (writable.writableNeedDrain) {\n      await wait();\n    }\n    for await (const chunk of iterable) {\n      if (!writable.write(chunk)) {\n        await wait();\n      }\n    }\n    if (end) {\n      writable.end();\n      await wait();\n    }\n    finish();\n  } catch (err) {\n    finish(error !== err ? aggregateTwoErrors(error, err) : err);\n  } finally {\n    cleanup();\n    writable.off('drain', resume);\n  }\n}\nasync function pumpToWeb(readable, writable, finish, {\n  end\n}) {\n  if (isTransformStream(writable)) {\n    writable = writable.writable;\n  }\n  // https://streams.spec.whatwg.org/#example-manual-write-with-backpressure\n  const writer = writable.getWriter();\n  try {\n    for await (const chunk of readable) {\n      await writer.ready;\n      writer.write(chunk).catch(() => {});\n    }\n    await writer.ready;\n    if (end) {\n      await writer.close();\n    }\n    finish();\n  } catch (err) {\n    try {\n      await writer.abort(err);\n      finish(err);\n    } catch (err) {\n      finish(err);\n    }\n  }\n}\nfunction pipeline(...streams) {\n  return pipelineImpl(streams, once(popCallback(streams)));\n}\nfunction pipelineImpl(streams, callback, opts) {\n  if (streams.length === 1 && ArrayIsArray(streams[0])) {\n    streams = streams[0];\n  }\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n  const ac = new AbortController();\n  const signal = ac.signal;\n  const outerSignal = opts === null || opts === undefined ? undefined : opts.signal;\n\n  // Need to cleanup event listeners if last stream is readable\n  // https://github.com/nodejs/node/issues/35452\n  const lastStreamCleanup = [];\n  validateAbortSignal(outerSignal, 'options.signal');\n  function abort() {\n    finishImpl(new AbortError());\n  }\n  addAbortListener = addAbortListener || require('../../ours/util').addAbortListener;\n  let disposable;\n  if (outerSignal) {\n    disposable = addAbortListener(outerSignal, abort);\n  }\n  let error;\n  let value;\n  const destroys = [];\n  let finishCount = 0;\n  function finish(err) {\n    finishImpl(err, --finishCount === 0);\n  }\n  function finishImpl(err, final) {\n    var _disposable;\n    if (err && (!error || error.code === 'ERR_STREAM_PREMATURE_CLOSE')) {\n      error = err;\n    }\n    if (!error && !final) {\n      return;\n    }\n    while (destroys.length) {\n      destroys.shift()(error);\n    }\n    ;\n    (_disposable = disposable) === null || _disposable === undefined ? undefined : _disposable[SymbolDispose]();\n    ac.abort();\n    if (final) {\n      if (!error) {\n        lastStreamCleanup.forEach(fn => fn());\n      }\n      process.nextTick(callback, error, value);\n    }\n  }\n  let ret;\n  for (let i = 0; i < streams.length; i++) {\n    const stream = streams[i];\n    const reading = i < streams.length - 1;\n    const writing = i > 0;\n    const end = reading || (opts === null || opts === undefined ? undefined : opts.end) !== false;\n    const isLastStream = i === streams.length - 1;\n    if (isNodeStream(stream)) {\n      if (end) {\n        const {\n          destroy,\n          cleanup\n        } = destroyer(stream, reading, writing);\n        destroys.push(destroy);\n        if (isReadable(stream) && isLastStream) {\n          lastStreamCleanup.push(cleanup);\n        }\n      }\n\n      // Catch stream errors that occur after pipe/pump has completed.\n      function onError(err) {\n        if (err && err.name !== 'AbortError' && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n          finish(err);\n        }\n      }\n      stream.on('error', onError);\n      if (isReadable(stream) && isLastStream) {\n        lastStreamCleanup.push(() => {\n          stream.removeListener('error', onError);\n        });\n      }\n    }\n    if (i === 0) {\n      if (typeof stream === 'function') {\n        ret = stream({\n          signal\n        });\n        if (!isIterable(ret)) {\n          throw new ERR_INVALID_RETURN_VALUE('Iterable, AsyncIterable or Stream', 'source', ret);\n        }\n      } else if (isIterable(stream) || isReadableNodeStream(stream) || isTransformStream(stream)) {\n        ret = stream;\n      } else {\n        ret = Duplex.from(stream);\n      }\n    } else if (typeof stream === 'function') {\n      if (isTransformStream(ret)) {\n        var _ret;\n        ret = makeAsyncIterable((_ret = ret) === null || _ret === undefined ? undefined : _ret.readable);\n      } else {\n        ret = makeAsyncIterable(ret);\n      }\n      ret = stream(ret, {\n        signal\n      });\n      if (reading) {\n        if (!isIterable(ret, true)) {\n          throw new ERR_INVALID_RETURN_VALUE('AsyncIterable', `transform[${i - 1}]`, ret);\n        }\n      } else {\n        var _ret2;\n        if (!PassThrough) {\n          PassThrough = require('./passthrough');\n        }\n\n        // If the last argument to pipeline is not a stream\n        // we must create a proxy stream so that pipeline(...)\n        // always returns a stream which can be further\n        // composed through `.pipe(stream)`.\n\n        const pt = new PassThrough({\n          objectMode: true\n        });\n\n        // Handle Promises/A+ spec, `then` could be a getter that throws on\n        // second use.\n        const then = (_ret2 = ret) === null || _ret2 === undefined ? undefined : _ret2.then;\n        if (typeof then === 'function') {\n          finishCount++;\n          then.call(ret, val => {\n            value = val;\n            if (val != null) {\n              pt.write(val);\n            }\n            if (end) {\n              pt.end();\n            }\n            process.nextTick(finish);\n          }, err => {\n            pt.destroy(err);\n            process.nextTick(finish, err);\n          });\n        } else if (isIterable(ret, true)) {\n          finishCount++;\n          pumpToNode(ret, pt, finish, {\n            end\n          });\n        } else if (isReadableStream(ret) || isTransformStream(ret)) {\n          const toRead = ret.readable || ret;\n          finishCount++;\n          pumpToNode(toRead, pt, finish, {\n            end\n          });\n        } else {\n          throw new ERR_INVALID_RETURN_VALUE('AsyncIterable or Promise', 'destination', ret);\n        }\n        ret = pt;\n        const {\n          destroy,\n          cleanup\n        } = destroyer(ret, false, true);\n        destroys.push(destroy);\n        if (isLastStream) {\n          lastStreamCleanup.push(cleanup);\n        }\n      }\n    } else if (isNodeStream(stream)) {\n      if (isReadableNodeStream(ret)) {\n        finishCount += 2;\n        const cleanup = pipe(ret, stream, finish, {\n          end\n        });\n        if (isReadable(stream) && isLastStream) {\n          lastStreamCleanup.push(cleanup);\n        }\n      } else if (isTransformStream(ret) || isReadableStream(ret)) {\n        const toRead = ret.readable || ret;\n        finishCount++;\n        pumpToNode(toRead, stream, finish, {\n          end\n        });\n      } else if (isIterable(ret)) {\n        finishCount++;\n        pumpToNode(ret, stream, finish, {\n          end\n        });\n      } else {\n        throw new ERR_INVALID_ARG_TYPE('val', ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'], ret);\n      }\n      ret = stream;\n    } else if (isWebStream(stream)) {\n      if (isReadableNodeStream(ret)) {\n        finishCount++;\n        pumpToWeb(makeAsyncIterable(ret), stream, finish, {\n          end\n        });\n      } else if (isReadableStream(ret) || isIterable(ret)) {\n        finishCount++;\n        pumpToWeb(ret, stream, finish, {\n          end\n        });\n      } else if (isTransformStream(ret)) {\n        finishCount++;\n        pumpToWeb(ret.readable, stream, finish, {\n          end\n        });\n      } else {\n        throw new ERR_INVALID_ARG_TYPE('val', ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'], ret);\n      }\n      ret = stream;\n    } else {\n      ret = Duplex.from(stream);\n    }\n  }\n  if (signal !== null && signal !== undefined && signal.aborted || outerSignal !== null && outerSignal !== undefined && outerSignal.aborted) {\n    process.nextTick(abort);\n  }\n  return ret;\n}\nfunction pipe(src, dst, finish, {\n  end\n}) {\n  let ended = false;\n  dst.on('close', () => {\n    if (!ended) {\n      // Finish if the destination closes before the source has completed.\n      finish(new ERR_STREAM_PREMATURE_CLOSE());\n    }\n  });\n  src.pipe(dst, {\n    end: false\n  }); // If end is true we already will have a listener to end dst.\n\n  if (end) {\n    // Compat. Before node v10.12.0 stdio used to throw an error so\n    // pipe() did/does not end() stdio destinations.\n    // Now they allow it but \"secretly\" don't close the underlying fd.\n\n    function endFn() {\n      ended = true;\n      dst.end();\n    }\n    if (isReadableFinished(src)) {\n      // End the destination if the source has already ended.\n      process.nextTick(endFn);\n    } else {\n      src.once('end', endFn);\n    }\n  } else {\n    finish();\n  }\n  eos(src, {\n    readable: true,\n    writable: false\n  }, err => {\n    const rState = src._readableState;\n    if (err && err.code === 'ERR_STREAM_PREMATURE_CLOSE' && rState && rState.ended && !rState.errored && !rState.errorEmitted) {\n      // Some readable streams will emit 'close' before 'end'. However, since\n      // this is on the readable side 'end' should still be emitted if the\n      // stream has been ended and no error emitted. This should be allowed in\n      // favor of backwards compatibility. Since the stream is piped to a\n      // destination this should not result in any observable difference.\n      // We don't need to check if this is a writable premature close since\n      // eos will only fail with premature close on the reading side for\n      // duplex streams.\n      src.once('end', finish).once('error', finish);\n    } else {\n      finish(err);\n    }\n  });\n  return eos(dst, {\n    readable: false,\n    writable: true\n  }, finish);\n}\nmodule.exports = {\n  pipelineImpl,\n  pipeline\n};","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}