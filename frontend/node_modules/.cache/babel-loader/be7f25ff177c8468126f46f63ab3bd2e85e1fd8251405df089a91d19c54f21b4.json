{"ast":null,"code":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nconst {\n  ObjectSetPrototypeOf,\n  Symbol\n} = require('../../ours/primordials');\nmodule.exports = Transform;\nconst {\n  ERR_METHOD_NOT_IMPLEMENTED\n} = require('../../ours/errors').codes;\nconst Duplex = require('./duplex');\nconst {\n  getHighWaterMark\n} = require('./state');\nObjectSetPrototypeOf(Transform.prototype, Duplex.prototype);\nObjectSetPrototypeOf(Transform, Duplex);\nconst kCallback = Symbol('kCallback');\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  // TODO (ronag): This should preferably always be\n  // applied but would be semver-major. Or even better;\n  // make Transform a Readable with the Writable interface.\n  const readableHighWaterMark = options ? getHighWaterMark(this, options, 'readableHighWaterMark', true) : null;\n  if (readableHighWaterMark === 0) {\n    // A Duplex will buffer both on the writable and readable side while\n    // a Transform just wants to buffer hwm number of elements. To avoid\n    // buffering twice we disable buffering on the writable side.\n    options = {\n      ...options,\n      highWaterMark: null,\n      readableHighWaterMark,\n      // TODO (ronag): 0 is not optimal since we have\n      // a \"bug\" where we check needDrain before calling _write and not after.\n      // Refs: https://github.com/nodejs/node/pull/32887\n      // Refs: https://github.com/nodejs/node/pull/35941\n      writableHighWaterMark: options.writableHighWaterMark || 0\n    };\n  }\n  Duplex.call(this, options);\n\n  // We have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n  this[kCallback] = null;\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  // Backwards compat. Some Transform streams incorrectly implement _final\n  // instead of or in addition to _flush. By using 'prefinish' instead of\n  // implementing _final we continue supporting this unfortunate use case.\n  this.on('prefinish', prefinish);\n}\nfunction final(cb) {\n  if (typeof this._flush === 'function' && !this.destroyed) {\n    this._flush((er, data) => {\n      if (er) {\n        if (cb) {\n          cb(er);\n        } else {\n          this.destroy(er);\n        }\n        return;\n      }\n      if (data != null) {\n        this.push(data);\n      }\n      this.push(null);\n      if (cb) {\n        cb();\n      }\n    });\n  } else {\n    this.push(null);\n    if (cb) {\n      cb();\n    }\n  }\n}\nfunction prefinish() {\n  if (this._final !== final) {\n    final.call(this);\n  }\n}\nTransform.prototype._final = final;\nTransform.prototype._transform = function (chunk, encoding, callback) {\n  throw new ERR_METHOD_NOT_IMPLEMENTED('_transform()');\n};\nTransform.prototype._write = function (chunk, encoding, callback) {\n  const rState = this._readableState;\n  const wState = this._writableState;\n  const length = rState.length;\n  this._transform(chunk, encoding, (err, val) => {\n    if (err) {\n      callback(err);\n      return;\n    }\n    if (val != null) {\n      this.push(val);\n    }\n    if (wState.ended ||\n    // Backwards compat.\n    length === rState.length ||\n    // Backwards compat.\n    rState.length < rState.highWaterMark) {\n      callback();\n    } else {\n      this[kCallback] = callback;\n    }\n  });\n};\nTransform.prototype._read = function () {\n  if (this[kCallback]) {\n    const callback = this[kCallback];\n    this[kCallback] = null;\n    callback();\n  }\n};","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}